{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Item Based Recommender System  \n",
    "-------------\n",
    "_Author: Carleton Smith_\n",
    "\n",
    "## Project Guide  \n",
    "-------------\n",
    " - [Project Overview](#project-overview)\n",
    " - [Reading in the Data](#read-in)\n",
    "     - [EDA](#eda)  \n",
    "       \n",
    "       \n",
    " - [Functioning of Recommender Systems](#simple)\n",
    "     - [Predicting Unknown Scores](#pred)  \n",
    "     \n",
    "     \n",
    " - [Return to the Data](#ret)\n",
    " - [Utilization Complexities](#util)\n",
    " - [SVD](#svd)\n",
    " - [Surprise - Python package](#surprise)  \n",
    " \n",
    " <a id = \"project-overview\"></a>\n",
    " ## Project Overview  \n",
    " --------  \n",
    " #### EXPECTED TIME: 2.5 HRS  \n",
    " \n",
    " This project consists of 4 parts:  \n",
    " \n",
    " - General Familiarization with the data.\n",
    " - Mathematical foundations of recommender systems and simple examples about them.\n",
    " - Execution of methods on the data.\n",
    " - Short introduction to the `Surprise` package.   \n",
    " \n",
    "The methods used below should all be familiar from the lectures in week 9. Except for SVD and the `Surprise` package, we will review some main concepts before demonstration.\n",
    "\n",
    "The general goal of this project is, given a collection of users, items, and user reviews of the items, predict what score a user would assign to an item they have yet to review.  \n",
    "\n",
    "We will be working with a synthetic review dataset, modeled on reviews from Amazon. To demonstrate the techniques, in all our examples, we will work only with a smaller portion of the made-up data.\n",
    "\n",
    "**Motivation:** Recommender systems provide a non-parametric comparisons between items. They are fundamentals in analyzing how individuals can be served.\n",
    "\n",
    "**Objectives:**  \n",
    "\n",
    "- Understand mathematical foundations of recommender systems.\n",
    "- Translation of mathematical algorithm into code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"questions\"></a>\n",
    "## Questions\n",
    "\n",
    "+ [Question 01](#q01)\n",
    "+ [Question 02](#q02)\n",
    "+ [Question 03](#q03)\n",
    "+ [Question 04](#q04)\n",
    "+ [Question 05](#q05)\n",
    "+ [Question 06](#q06)\n",
    "+ [Question 07](#q07)\n",
    "+ [Question 08](#q08)\n",
    "+ [Question 09](#q09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Reading the data\n",
    "In the first part of this assignment, we will be using synthetic data modeled from Amazon reviews. A description of the review data and instructions to download the database [can be found here](https://s3.amazonaws.com/amazon-reviews-pds/readme.html).  \n",
    "\n",
    "Below we display a sample of the data taken from Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>18778586</td>\n",
       "      <td>RDIJS7QYB6XNR</td>\n",
       "      <td>B00EDBY7X8</td>\n",
       "      <td>122952789</td>\n",
       "      <td>Monopoly Junior Board Game</td>\n",
       "      <td>Toys</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent!!!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>24769659</td>\n",
       "      <td>R36ED1U38IELG8</td>\n",
       "      <td>B00D7JFOPC</td>\n",
       "      <td>952062646</td>\n",
       "      <td>56 Pieces of Wooden Train Track Compatible wit...</td>\n",
       "      <td>Toys</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Good quality track at excellent price</td>\n",
       "      <td>Great quality wooden track (better than some o...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>44331596</td>\n",
       "      <td>R1UE3RPRGCOLD</td>\n",
       "      <td>B002LHA74O</td>\n",
       "      <td>818126353</td>\n",
       "      <td>Super Jumbo Playing Cards by S&amp;S Worldwide</td>\n",
       "      <td>Toys</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>Cards are not as big as pictured.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>23310293</td>\n",
       "      <td>R298788GS6I901</td>\n",
       "      <td>B00ARPLCGY</td>\n",
       "      <td>261944918</td>\n",
       "      <td>Barbie Doll and Fashions Barbie Gift Set</td>\n",
       "      <td>Toys</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>my daughter loved it and i liked the price and...</td>\n",
       "      <td>my daughter loved it and i liked the price and...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>US</td>\n",
       "      <td>38745832</td>\n",
       "      <td>RNX4EXOBBPN5</td>\n",
       "      <td>B00UZOPOFW</td>\n",
       "      <td>717410439</td>\n",
       "      <td>Emazing Lights eLite Flow Glow Sticks - Spinni...</td>\n",
       "      <td>Toys</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>DONT BUY THESE!</td>\n",
       "      <td>Do not buy these! They break very fast I spun ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     18778586   RDIJS7QYB6XNR  B00EDBY7X8       122952789   \n",
       "1          US     24769659  R36ED1U38IELG8  B00D7JFOPC       952062646   \n",
       "2          US     44331596   R1UE3RPRGCOLD  B002LHA74O       818126353   \n",
       "3          US     23310293  R298788GS6I901  B00ARPLCGY       261944918   \n",
       "4          US     38745832    RNX4EXOBBPN5  B00UZOPOFW       717410439   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0                         Monopoly Junior Board Game             Toys   \n",
       "1  56 Pieces of Wooden Train Track Compatible wit...             Toys   \n",
       "2         Super Jumbo Playing Cards by S&S Worldwide             Toys   \n",
       "3           Barbie Doll and Fashions Barbie Gift Set             Toys   \n",
       "4  Emazing Lights eLite Flow Glow Sticks - Spinni...             Toys   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            5              0            0    N                 Y   \n",
       "2            2              1            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            1              1            1    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                         Five Stars   \n",
       "1              Good quality track at excellent price   \n",
       "2                                          Two Stars   \n",
       "3  my daughter loved it and i liked the price and...   \n",
       "4                                    DONT BUY THESE!   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                       Excellent!!!  2015-08-31  \n",
       "1  Great quality wooden track (better than some o...  2015-08-31  \n",
       "2                  Cards are not as big as pictured.  2015-08-31  \n",
       "3  my daughter loved it and i liked the price and...  2015-08-31  \n",
       "4  Do not buy these! They break very fast I spun ...  2015-08-31  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data_path = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/sample_us.tsv\"\n",
    "\n",
    "rev_df = pd.read_table(sample_data_path)\n",
    "\n",
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Looking at our raw data\n",
    "\n",
    "Although Natural Language Processing (NLP) might offer insight into the structure of reviews, for this assignment, we are only interested in the customers (`costumer_id`), the products (`product_id`), and the scores (`star_rating`) that each costumer assigned to a particular product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>18778586</td>\n",
       "      <td>B00EDBY7X8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24769659</td>\n",
       "      <td>B00D7JFOPC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>44331596</td>\n",
       "      <td>B002LHA74O</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>23310293</td>\n",
       "      <td>B00ARPLCGY</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>38745832</td>\n",
       "      <td>B00UZOPOFW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  score\n",
       "0     18778586  B00EDBY7X8      5\n",
       "1     24769659  B00D7JFOPC      5\n",
       "2     44331596  B002LHA74O      2\n",
       "3     23310293  B00ARPLCGY      5\n",
       "4     38745832  B00UZOPOFW      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df = rev_df[['customer_id','product_id', 'star_rating']]\n",
    "rev_df.rename(columns= {'star_rating':'score'}, inplace=True)\n",
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q01\"></a>\n",
    "[Return to top](#questions)\n",
    "\n",
    "### Question 01\n",
    "\n",
    "Above, in our `ref_df` Database, we used the attribute `rename` to rename the column `star_rating` as `score` by passing a dictionary as a parameter.\n",
    "\n",
    "Which other object, when passed to `columns`, would have yielded the same result?\n",
    "\n",
    "- a) \"reviewerID, productID, score\"\n",
    "- b) \"['asin':'productID','overall':'score']\"\n",
    "- c) \"['customer_id', 'product_id', 'score']\"\n",
    "- d) None of the above.\n",
    "\n",
    "Assign the letter associated with your choice as a string to ans1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#Which other object, when passed to `columns`, would have yielded the same result?\n",
    "#a) \"reviewerID, productID, score\"\n",
    "#b) \"['asin':'productID','overall':'score']\"\n",
    "#c) \"['customer_id', 'product_id', 'score']\"\n",
    "#d) None of the above.\n",
    "\n",
    "#Assign the letter associated with your choice as a string to ans1.\n",
    "### YOUR SOLUTION HERE\n",
    "ans1 = \"b\"\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-01",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Although this is not strictly necessary, we can modify the values in columns customer_id and product_id to make them a little easier to read.  \n",
    "\n",
    "We will do so by building two dictionaries: one for `costumer_id` and the other one for `product_id` in the following way.\n",
    "\n",
    "Let the keys for your dictionary be all the *n unique* values of `costumer_id`. Rewrite such values to read \"R\" followed by a number ###, from 0 to n, such that each unique key is mapped to a unique string of the format `R###`. We do the same for the products, but using \"P\" as a prefix instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B00EDBY7X8 : P0\n",
      "B00D7JFOPC : P1\n",
      "B002LHA74O : P2\n",
      "B00ARPLCGY : P3\n",
      "B00UZOPOFW : P4\n",
      "length:  49\n"
     ]
    }
   ],
   "source": [
    "rID_dict = {rID:'R'+ str(idx) for idx, rID in enumerate(rev_df['customer_id'].unique()) }\n",
    "pID_dict = {pID:'P'+ str(idx) for idx, pID in enumerate(rev_df['product_id'].unique()) }\n",
    "\n",
    "\n",
    "### Checking the values in the dictionaries below for products.\n",
    "for k in list(pID_dict.keys())[:5]:\n",
    "    print(k, \":\",pID_dict[k])\n",
    "print(\"length: \",len(pID_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, we rename the costumers and products IDs in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>R0</td>\n",
       "      <td>P0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>R1</td>\n",
       "      <td>P1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>R2</td>\n",
       "      <td>P2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>R3</td>\n",
       "      <td>P3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>R4</td>\n",
       "      <td>P4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id product_id  score\n",
       "0          R0         P0      5\n",
       "1          R1         P1      5\n",
       "2          R2         P2      2\n",
       "3          R3         P3      5\n",
       "4          R4         P4      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.loc[:, 'product_id'] = rev_df.loc[:,'product_id'].map(pID_dict)\n",
    "rev_df.loc[:, 'customer_id'] = rev_df.loc[:,'customer_id'].map(rID_dict)\n",
    "\n",
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"Exploratory Data Analysis\"></a>\n",
    "### Exploratory Data Analysis (EDA)\n",
    "Having gone through the process of cleaning and analyzing the data, we will load a more extensive synthetic dataset and perform some light EDA to look at the distributions of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'./data/synthetic_reviews.csv' does not exist: b'./data/synthetic_reviews.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-49020c7cdc59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msynth_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/synthetic_reviews.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrev_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynth_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrev_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./data/synthetic_reviews.csv' does not exist: b'./data/synthetic_reviews.csv'"
     ]
    }
   ],
   "source": [
    "# Reading the data\n",
    "synth_data_path = \"./data/synthetic_reviews.csv\"\n",
    "\n",
    "rev_df = pd.read_csv(synth_data_path)\n",
    "rev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "First, we visualize how many products got a score of 5, 4, 3, 2, or 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rev_df['score'].value_counts().plot(kind = 'bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, we count how many products received a specific score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rev_df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We notice that there is an interesting preponderance of products with score 5. \n",
    "\n",
    "We continue by ranking the product from the ones that had the most reviews to the ones that had the least. We display the first 15 and the last 5 rows of this ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Reviews per product, top and bottom reviewed\\n\")\n",
    "#Display first 15 rows\n",
    "print(rev_df['productID'].value_counts()[:15])\n",
    "#Display last 5 rows\n",
    "print(rev_df['productID'].value_counts()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Below, we visualize the ranking defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "product_w_n_reviews = rev_df['productID'].value_counts().value_counts()\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.scatter(product_w_n_reviews.index, product_w_n_reviews)\n",
    "plt.xlabel(\"Number of Reviews\", fontsize = 16)\n",
    "plt.ylabel(\"Number of Products\", fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The above graph seem to be on a log-normal scale. \n",
    "\n",
    "In reality, the graph displayed has the shape of a \"hollow curve\". The log-normal appearance is an artifact of the data synthesis.\n",
    "\n",
    "We will continue our EDA by ranking which costumers gave the most and least number of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(\"Reviews per reviewer, top and bottom reviewers\\n\")\n",
    "print(rev_df['reviewerID'].value_counts()[:15])\n",
    "print(rev_df['reviewerID'].value_counts()[-5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Again, we visualize the ranking defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "product_w_n_reviews = rev_df['reviewerID'].value_counts().value_counts()\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.scatter(product_w_n_reviews.index, product_w_n_reviews)\n",
    "plt.xlabel(\"Number of Reviews\", fontsize = 16)\n",
    "plt.ylabel(\"Number of Users\", fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "As expected, most products are only reviewed a few times, most users only submit a few reviews, and very few users have submitted many reviews. \n",
    "\n",
    "Again. the above graph has the shape of a \"hollow curve\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"simple\"></a>\n",
    "### Functioning of Recommender Systems\n",
    "\n",
    "Before tackling our extensive synthetic data, we will use a simpler dataset to demonstrate the functioning of recommender systems.  \n",
    "\n",
    "Below we have a set of rankings of six musicians made by six individuals.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "example_path = \"./data/example.csv\"\n",
    "ex = pd.read_csv(example_path, index_col = 0)\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Note that the value \"0\" in the rows above denotes the absence of ranking - NOT an extremely poor ranking.  \n",
    "\n",
    "To determine which product to recommend, we can compute the similarity scores between products. Similarity scores can be computed in three different ways:\n",
    "\n",
    "- the Euclidean distance,\n",
    "- the Pearson's correlation coefficient,\n",
    "- and the cosine similarity score. \n",
    "\n",
    "To compare these scores we will normalize each to range between 0 and 1.  \n",
    "To simplify our analysis, we will use a subset of our example DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ex_hand = ex.iloc[:3,-3:]\n",
    "ex_hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Euclidean Distance\n",
    "\n",
    "The Euclidean distance between and point $i =(a_i, b_i, \\dots, n_i)$ and $j= (a_j, b_j, \\dots, n_j)$ is given by\n",
    "\n",
    "$$\\sqrt{(a_j-a_i)^2+(b_j-b_i)^2+...+(n_j-n_i)^2}$$  \n",
    "\n",
    "\n",
    "<a id=\"q02\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 02\n",
    "\n",
    "Calculate the Euclidean distance between Brahms and Wagner in the `ex_hand` DataFrame. \n",
    "\n",
    "\n",
    "Assign the computed distance as a float to the variable ans2. Make sure that is answer is accurate to 3 decimal places. Feel free to use the KNN assignment as a reference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "# Calculate the Euclidean distance between Brahms and Wagner in the `ex_hand` DataFrame\n",
    "# Assign the computed distance as a float to the variable ans2. Make sure that is answer is \n",
    "# accurate to 3 decimal places. Feel free to use the KNN assignment as a reference.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans2 = ...\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-02",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "To normalize the Euclidean distance between 0 and 1, we can use the following formula that relates \"distance\" to \"similarity\"\n",
    "\n",
    "$$\\text{similarity} =\\frac1{1+\\text{distance}}.$$\n",
    "\n",
    "For example, a distance of 0 corresponds to a similarity of 1, and a very large distance (e.g., $\\infty$) corresponds to a similarity of 0.  \n",
    "\n",
    "<a id=\"q03\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 03\n",
    "\n",
    "Define a  function called `e_sim` that accepts two `pandas` series as arguments.\n",
    "\n",
    "Your function should return the euclidean similarity score between the two series. Make sure that is answer is accurate to 3 decimal places.\n",
    "\n",
    "For this question you will need to use the attribute `np.linalg.norm()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "# Define a  function called `e_sim` that accepts two `pandas` series as arguments.\n",
    "# Your function should return the euclidean similarity score between the two series. \n",
    "# Make sure that is answer is accurate to 3 decimal places.\n",
    "\n",
    "# For this question you will need to use the attribute `np.linalg.norm()`.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def e_sim(ser1, ser2):\n",
    "    \"\"\"\n",
    "    Given two Pandas series, compute the euclidean similarity score;\n",
    "        1 / 1+euclidean distance\n",
    "        \n",
    "    Positional Arguments --\n",
    "        ser1: a Pandas Series of length n\n",
    "        ser2: a Pandas Series of length n\n",
    "    \n",
    "    Example --\n",
    "        ser1 = ex_hand.iloc[:,0]\n",
    "        ser2 = ex_hand.iloc[:,1]\n",
    "        print(e_sim(ser1, ser2)) #--> 0.28989794855663564\n",
    "    \"\"\"\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-03",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Pearson's Correlation Coefficient\n",
    "\n",
    "The Pearson's correlation coefficient $\\rho$ takes values from -1 to 1. Therefore, to normalize it into a difference score between 0 and 1, we need to reduce that range by half (i.e., divide the range by two) to increase the minimum score to 0, and add .5:  \n",
    "\n",
    "$$\\frac12 + \\frac{\\rho_{xy}}2$$  \n",
    "\n",
    "The function below computes the Pearson's correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Function to define the Pearson's Correlation Coefficient.\n",
    "def p_sim(ser1, ser2):\n",
    "    \n",
    "    def normalize(raw):\n",
    "        return .5 + (raw/2)\n",
    "    \n",
    "    corr = np.corrcoef(ser1, ser2)[0][1] ### returns 2x2 array with correlation to self(1) on diagonal\n",
    "    \n",
    "    return normalize(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "#### Cosine Similarity\n",
    "\n",
    "The cosine similarity calculates the cosine of the angle between two vectors normalizing it between 0 and 1.  \n",
    "\n",
    "<a id=\"q04\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 04\n",
    "\n",
    "Decide whether the following statement is true or false.\n",
    "\n",
    "*Like the correlation coefficient similarity score, the cosine similarity score is unaffected by magnitudes. For example, an excited user who gives mostly 5's will be considered similar to a user who gives mostly 2's.*\n",
    "\n",
    "Assign a Boolean value to the variable ans1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#Decide whether the following statement is true or false.\n",
    "\n",
    "#*Like the correlation coefficient similarity score, the cosine similarity score is \n",
    "# unaffected by magnitudes. For example, an excited user who gives mostly 5's will be \n",
    "# considered similar to a user who gives mostly 2's.*\n",
    "\n",
    "#Assign a Boolean value to the variable ans1.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans1 = ...\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-04",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The cosine similarity score is given by the following formula\n",
    "\n",
    "$$cos(\\theta) = \\frac{S1\\cdot S2}{||S1||\\cdot||S2||},$$\n",
    " \n",
    " where $S1$ and $S2$ are the two vectors considered, and $||\\cdot||$ represents the magnitude of each vector.\n",
    " \n",
    "The function below computes the cosine similarity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###Function to define the cosine similarity.\n",
    "\n",
    "def c_sim(ser1, ser2):\n",
    "    def normalize(raw):\n",
    "        return .5 + (raw/2)\n",
    "    \n",
    "    cosT = np.dot(ser1, ser2) / (np.linalg.norm(ser1)* np.linalg.norm(ser2))\n",
    "    \n",
    "    return normalize(cosT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "At this point we have defined three functions for calculating similarity between two vectors.  \n",
    "\n",
    "- e_sim: for the Euclidean similarity \n",
    "- p_sim: for the Pearson correlation coefficient similarity\n",
    "- c_sim: for the cosine similarity\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Now, let's calculate each of the three similarity scores for each pair of musicians in the `ex` DataFrame.  \n",
    "\n",
    "Let's remind us of what the DataFrame `ex` looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The function we will build must take into account that not all users have rated all musicians.\n",
    "\n",
    "So, for example, when comparing \"Mozart\" and \"Bach\", we must disregard the observations from \"Abel\" and \"Baker\", respectively.  \n",
    "\n",
    "This can be done by reading the value \"0\" as to be \"less than 1\", and *not* as the lack of information which actually represents.  \n",
    "\n",
    "\n",
    "<a id=\"q05\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 05\n",
    "Define a  function called `drop_val` that accepts the following  arguments:\n",
    "\n",
    "- A `pandas` DataFrame.\n",
    "- A numeric variable named `to_drop`.\n",
    "\n",
    "Your function should drop all the rows that have the value contained in `to_drop` in any column, and should return the DataFrame without the rows that have been dropped.\n",
    "\n",
    "For example, if we pass the DataFrame `ex` containing all rows but only the columns corresponding to \"Mozart\" and \"Bach\", and we set  'to_drop=5', our function should return \"Abel\", \"Erik\", and \"Frank\" rows with all the original columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#Define a function called drop_val that accepts the following arguments:\n",
    "# - A pandas DataFrame.\n",
    "# - A numeric variable named to_drop.\n",
    "\n",
    "# Your function should drop all the rows that have the value contained in to_drop in any column, \n",
    "# and should return the DataFrame without the rows that have been dropped.\n",
    "\n",
    "# For example, if we pass the DataFrame ex containing all rows but only the columns corresponding\n",
    "# to \"Mozart\" and \"Bach\", and we set 'to_drop=5', our function should return \"Abel\", \"Erik\", and \"Frank\" \n",
    "# rows with all the original columns.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "def drop_val (df, to_drop):\n",
    "    \n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame containing the specified values\n",
    "    \n",
    "    Positional Arguments --\n",
    "        df: a Pandas DataFrame\n",
    "        to_drop: a value found in some rows of df\n",
    "    \n",
    "    Example --\n",
    "        \n",
    "        df = ex.loc[:,\"Mozart\":\"Bach]\n",
    "        to_drop = 5\n",
    "        print(drop_val(df,to_drop)) # -->          Mozart  Bach\n",
    "                                            Abel        0     1\n",
    "                                            Erik        3     3\n",
    "                                            Frank       2     2   \n",
    "    \"\"\"\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "    return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-05",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The cell below defines a function \"drop_rows_with_zeros\" that takes a DataFrame with two columns and returns a DataFrame where all the rows that contain a value of 0 have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Defining drop_rows_with_zeros\n",
    "\n",
    "def drop_rows_with_zeros(df):\n",
    "    keep = np.intersect1d( np.nonzero(df.iloc[:,0]), np.nonzero(df.iloc[:,1]))\n",
    "    \n",
    "    return df.iloc[keep,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### Comparison of Similarity Scores\n",
    "\n",
    "Below, we will compare the similarity scores for each each combination of musicians. \n",
    "\n",
    "First, we find all the possible pairs of musicians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "for c in itertools.combinations(ex.columns,2):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Each tuple can be used as a subset in the DataFrame. For example, the subset for Mozart and Bach is given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ex[list(('Mozart', 'Bach'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Next, we define a first dictionary that has as keys the pairs musicians being compared.\n",
    "\n",
    "In a second dictionary, we define the similarity scores, \"Euclid\", \"Pearson\", and \"Cosine\",  corresponding to each pair of musician."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sim_scores = dict()\n",
    "\n",
    "for c in itertools.combinations(ex.columns, 2):\n",
    "    df = drop_rows_with_zeros(ex[list(c)])\n",
    "    ser1 = df.iloc[:,0]\n",
    "    ser2 = df.iloc[:,1]\n",
    "    scores = {\"Euclid\":e_sim(ser1, ser2), \"Pearson\":p_sim(ser1,ser2), \"Cosine\":c_sim(ser1,ser2)}\n",
    "    key =\", \".join(c)\n",
    "    sim_scores[key] = scores\n",
    "    \n",
    "sims = pd.DataFrame.from_dict(sim_scores,orient = \"index\")\n",
    "sims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The similarity scores can be visualized as follow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Note: x and y scales are not consistent in this visualization\n",
    "sns.pairplot(sims );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Visualization with consistent x and y scales using `matplotlib`\n",
    "plt.figure(figsize = (12,6))\n",
    "for i, cols in enumerate([('Euclid','Pearson'), (\"Euclid\",\"Cosine\"),(\"Pearson\",\"Cosine\")]):\n",
    "    plt.subplot(1,3,i+1)\n",
    "    \n",
    "    plt.scatter(sims[cols[0]], sims[cols[1]])\n",
    "    \n",
    "    plt.xlabel(cols[0], fontsize = 14); plt.ylabel(cols[1], fontsize = 14)\n",
    "    plt.xlim(0,1); plt.ylim(0,1)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"sim-note\"></a>\n",
    "#### Differences in Similarity Scores\n",
    "\n",
    "\n",
    "As we can see from the graphs above, it is possible to visualize a range of similarity scores given different techniques. These similarity scores will majorly impact how a recommender system performs. \n",
    "\n",
    "Refer to the lectures for the particular impacts and strengths of the different similarity calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = 'pred'></a>\n",
    "### Predicting Unknown Scores\n",
    "\n",
    "Assume that we don't know the score that Abel gave to Mozart. To do so, we must take into account that Mozart has a similarity score in relation to all the other musicians.\n",
    "\n",
    "Similarly, Abel has given a score to all the other musicians.  \n",
    "\n",
    "Therefore, Abel's predicted score for Mozart will be given by: the **sum** of Abel's score for every other musician **times** that musician's similarity score with respect to Mozart, **divided by** the sum of similarity scores.  \n",
    "\n",
    "For example, we can predict Abel's score for Mozart by computing\n",
    "\n",
    "$$\\frac{\\sum_{ mus = Bach}^{Liszt}A_{mus}*\\text{simScore}(\\text{Mozart, mus})}{\\sum_{mus = Bach}^{Liszt}\\text{simScore}{\\text{(Mozart, mus)}}}$$ \n",
    "\n",
    "The commands below compute the similarity scores for Mozart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "mozSimScores = {}\n",
    "for mus in ex.columns[1:]:\n",
    "    no_zeros = drop_rows_with_zeros(ex[['Mozart', mus]])\n",
    "    \n",
    "    mozSimScores[mus] = round(p_sim(no_zeros.iloc[:,0], no_zeros.iloc[:,1]),2)\n",
    "\n",
    "print(mozSimScores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q06\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 06\n",
    "\n",
    "Given the similarity scores calculated and stored in `mozSimScores`, use the above formula to predict Abel's score for Mozart. Assign your result to the variable ans1.Make sure that is answer is accurate to 3 decimal places.\n",
    "\n",
    "*Hint*: Use the rounded score computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "# Given the similarity scores calculated and stored in `mozSimScores`, use the above \n",
    "# formula to predict Abel's score for Mozart. Assign your result to the variable ans1.\n",
    "# Make sure that is answer is accurate to 3 decimal places.\n",
    "\n",
    "\n",
    "# *Hint*: Use the rounded score computed above.\n",
    "\n",
    "###  YOUR SOLUTION HERE\n",
    "\n",
    "ans1 = ...\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-06",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We observe that, although many other users gave Mozart high scores, because Abel appears to be less generous in his reviews, his predicted score for Mozart is fairly low. \n",
    "\n",
    "The function defined below predicts an unknown score based on the formula above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Creating a function to create predictions in the manner described above.\n",
    "### Note: \"user\" is a row, and \"item\" is a column in the df.\n",
    "### simFunc defaults to p_sim\n",
    "\n",
    "def scorePred(df, user, item, simFunc = p_sim, rev_items = None):\n",
    "    \"\"\"\n",
    "    Positional Arguments --\n",
    "        df: Pandas DataFrame\n",
    "        user: Row-index in df\n",
    "        item: Column-index in df\n",
    "        simFunc: a similarity function (e_sim, p_sim, or c_sim)\n",
    "        rev_items: For larger dfs, specifies all items reviewed by \"user\"\n",
    "    \"\"\"\n",
    "    # Check to see if user has already scored item\n",
    "    if df.loc[user,item] > 0:\n",
    "        return \"Already rated a \"+str(df.loc[user,item])\n",
    "    \n",
    "    # rev_items used for larger DataFrame,\n",
    "    # when you have all the items a particular user has reviewed already\n",
    "    # otherwise, if \"None\" (if statement below)\n",
    "    # take all other items other than item to predict\n",
    "    if not rev_items:\n",
    "        rev_items = set(df.columns)\n",
    "        rev_items.remove(item)\n",
    "    \n",
    "    sim_total, user_sim_total = 0,0\n",
    "    \n",
    "    for other_item in rev_items:\n",
    "        user_score_other_item = df.loc[user, other_item] # grab user score\n",
    "        \n",
    "        if user_score_other_item == 0:\n",
    "            print(\"no user score\")\n",
    "            continue\n",
    "        \n",
    "        # Use function built above to drop all other users with \"other_item\" score of \"0\"\n",
    "        no_zeros = drop_rows_with_zeros(df[[item, other_item]]) \n",
    "        sh = no_zeros.shape\n",
    "        \n",
    "        # If no other users, move to next item\n",
    "        if sh[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        #print(no_zeros.shape)\n",
    "        \n",
    "        # calculate similarity score using non-zero information. \n",
    "        ser1 = no_zeros.iloc[:,0]\n",
    "        ser2 = no_zeros.iloc[:,1]\n",
    "        # print(ser1, ser2)\n",
    "        ss = simFunc(no_zeros.iloc[:,0], no_zeros.iloc[:,1])\n",
    "        # print(ss, user_score_other_item)\n",
    "        \n",
    "        # add up sim total and weighted sim total\n",
    "        sim_total += ss\n",
    "        user_sim_total += user_score_other_item * ss\n",
    "\n",
    "        \n",
    "    if sim_total == 0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return user_sim_total / sim_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Use the cells below to compute the unknown score for different cases using the function `scorePred` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorePred(ex, 'Baker', 'Bach')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"ret\"></a>\n",
    "### Returning to the Data\n",
    "Let's go back to the Amazon rating DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "rev_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We observe that now the data does not conform to the two-dimensional n-by-p matrix that we have been using. Therefore, we need to manipulate our data. To do so we will use `Pandas` built-in `pivot()` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Reviewers on rows, item on cols. \n",
    "reshaped_reviews = rev_df.pivot(index = 'reviewerID', columns = 'productID')\n",
    "reshaped_reviews.fillna(0, inplace = True) # turns NA into 0\n",
    "reshaped_reviews.columns = reshaped_reviews.columns.droplevel() # removes artifact of pivot function\n",
    "\n",
    "\n",
    "print(\"shape: \", reshaped_reviews.shape)\n",
    "reshaped_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "It should be clear from the output above that the majority of the entries corresponding to a certain pair of costumer and product are now empty. Thus, when trying to provide recommendations, it will not be possible to predict scores for every  combination of costumer and product. In fact, to predict scores, we require a certain amount of overlap between the data.\n",
    "\n",
    "Below predictions are created for our reviewer called \"R0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### First, find the products that 'R0' has reviewed.\n",
    "### These are the products that will be used for creating similarity scores.\n",
    "\n",
    "r0 = reshaped_reviews.loc[\"R0\", :]\n",
    "# numpy function returns all indexes that are not \"0\"\n",
    "r0_nonzero = np.nonzero(r0)\n",
    "# collect names of reviewed products\n",
    "r0_rev_prods = list(r0.iloc[r0_nonzero].index) \n",
    "print(len(r0_rev_prods))\n",
    "r0_rev_prods[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a list containing the product that have not been reviewed by R0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Creating a list of products not reviewed by R0\n",
    "\n",
    "# return list of all prods not in the \"reviewed\" list\n",
    "r0_not_rev = np.setdiff1d(reshaped_reviews.columns, r0_rev_prods) \n",
    "\n",
    "print(len(r0_not_rev))\n",
    "r0_not_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The commands below requires too much processing for Vocareum. We simply display the output below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ### predict scores for products not yet reviewed by R0, using function built above: `scorePred`\n",
    "# ### cosine similarity used because if a product all has only one value of review (e.g. all 5s)\n",
    "# ### then the standard_deviation is 0 and the correlation coefficient is not calculable\n",
    "\n",
    "# preds = {}\n",
    "# for item in r0_not_rev:\n",
    "#     preds[item] = scorePred(reshaped_reviews, 'R0', item, simFunc = c_sim, rev_items = r0_rev_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# pd.Series(preds).sort_values(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Running the above cells took the local machine ~7.5'. results in the picture below.\n",
    "![preds](./data/r0_preds.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"util\"></a>\n",
    "### Utilization Complexities\n",
    "\n",
    "Certainly, if  a product is likely to score a \"5\", then that product should be recommended. However, because we are dealing with very sparse data, the confidence in our predictions will vary between each product.\n",
    "\n",
    "<a id=\"q07\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 07\n",
    "\n",
    "Consider 3 products: `A`, `B`, and `X`. Assume that `userN` has ranked both products `A`, and `B` with a score of 5. Assume that `user1` has ranked products `A`, and `X` both with score 3 and assume that user2 has ranked products `B` and `X` with score 2.\n",
    "\n",
    "What will be the similarity score between product `A` and product `X`? Assign the result the the variable ans1.\n",
    "\n",
    "What will be the similarity score between product `B` and product `X`? Assign the result the the variable ans2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "# Consider 3 products: `A`, `B`, and `X`. Assume that `userN` has ranked both products `A`, and `B` \n",
    "# with a score of 5. Assume that `user1` has ranked products `A`, and `X` both with score 3 and assume \n",
    "# that user2 has ranked products `B` and `X` with score 2.\n",
    "\n",
    "# What will be the similarity score between product `A` and product `X`? Assign the result the the variable ans1.\n",
    "\n",
    "#What will be the similarity score between product `B` and product `X`? Assign the result the the variable ans2.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans1 = ...\n",
    "ans2 = ...\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-07",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q08\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 08\n",
    "\n",
    "Given your answer above, what will be the predicted score of `userN` for product `X`?\n",
    "\n",
    "Assign your result to the variable ans1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "#Given your answer above, what will be the predicted score of `userN` for product `X`?\n",
    "\n",
    "#Assign your result to the variable ans1.\n",
    "###  YOUR SOLUTION HERE\n",
    "ans1 = ...\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-08",
     "locked": true,
     "points": "15",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "it is important to note that we could have run into other possible scenarios: high similarity scores because of few overlapping reviews, or high-user score for the user who is being predicted for.  \n",
    "\n",
    "<a id = \"svd\"></a>\n",
    "### Singular Value Decomposition (SVD)\n",
    "\n",
    "We can deal with the sparsity of data and, at the same time, increase the speed of our algorithm,  by using Singular Value Decomposition (SVD). SVD is a technique that reduces the dimensionality of functions by \"capturing\" a majority of the information present in a dataset in a smaller number of variables.  \n",
    "\n",
    "SVD relies upon some straight-forward linear algebra that is worth understanding. The main concept have been covered  in the lectures. Here are some more insightful resources about SVD.  \n",
    "\n",
    "[Here is a nice introduction.](https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/)  \n",
    "\n",
    "[Below, we will use `numpy's` implementation of SVD](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.linalg.svd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We have learned that the quantity $\\Sigma ^2$ describes the variance of each vector. The plot below displays the rate of the variance given by n vectors as a function of the total number of products.\n",
    "\n",
    "![svd](./assets/svd.PNG)\n",
    "\n",
    "We notice that about 1700 of the decomposed vectors will give around 80% of the variance in the data. Computationally, this will make the calculations much faster: in fact, considering only 1/3 of the vectors will yield 80% of the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# # Perform SVD\n",
    "# u, sigma, _ = np.linalg.svd(reshaped_reviews)\n",
    "\n",
    "# # Create function to decompose DataFrame\n",
    "# def return_svd(df , u, sigma, n):\n",
    "    \n",
    "#     sigN = np.mat(np.eye(n) * sigma[:n]) #arrange Sig4 into a diagonal matrix\n",
    "    \n",
    "#     n_svd_vectors = np.dot(df.T, np.dot(u[:,:n] , sigN.I))  #create transformed items\n",
    "    \n",
    "#     return pd.DataFrame(n_svd_vectors).T\n",
    "\n",
    "# # use function to create decomposed DataFrame\n",
    "# svd_df = return_svd(reshaped_reviews, u, sigma, 1700)\n",
    "# svd_df.columns = reshaped_reviews.columns\n",
    "\n",
    "# # Save DataFrame\n",
    "\n",
    "# svd_df.to_csv(\"svd_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The commands above take too long to run for Vocareum. The results are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "svd_df = pd.read_csv(\"./data/svd_df.csv\", index_col = 0)\n",
    "svd_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "As `svd_df` indicates, the svd vectors correspond to different items. The calculation for the recommendation will be the same, but will be done by using these new values.  \n",
    "\n",
    "For example, to predict the score that reviewer \"R0\" would give to  the product 'P1' (Remember \"R0\" already reviewed \"P0\") we must follow the following steps:  \n",
    "\n",
    "1. Find the products that R0 scored.\n",
    "2. Find the similarity between those scored products and \"P1\"\n",
    "3. Multiply those similarity scores by the scores from R0\n",
    "4. Divide by sum of similarity scores.  \n",
    "\n",
    "The downside of SVD is that it must be performed before the calculations, and, as was seen above, such computations can take some time. In fact, in practice, SVD would need to be performed each time a new review is added.\n",
    "\n",
    "The following function computes the prediction scores from the `svd_df` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Creating a function to create predictions using the SVD_df\n",
    "### Note: \"user\" is a row, and \"item\" is a column in the df, and a column in svd_df.\n",
    "### simFunc defaults to p_sim\n",
    "\n",
    "def scorePredSVD(df, user, item, svd_df, simFunc = p_sim, rev_items = None):\n",
    "    \n",
    "    # Check to see if user has already scored item\n",
    "    if df.loc[user,item] > 0:\n",
    "        return \"Already rated a \"+str(df.loc[user,item])\n",
    "    \n",
    "    # Code below should be familiar from \"scorePred\" defined above\n",
    "    if not rev_items:\n",
    "        rev_items = set(df.columns)\n",
    "        rev_items.remove(item)\n",
    "    \n",
    "    sim_total, user_sim_total = 0,0\n",
    "    \n",
    "    for other_item in rev_items:\n",
    "        user_score_other_item = df.loc[user, other_item]\n",
    "        \n",
    "        if user_score_other_item == 0:\n",
    "            print(\"no user score\")\n",
    "            continue\n",
    "            \n",
    "        ser1 = svd_df.loc[:,item]\n",
    "        ser2 = svd_df.loc[:,other_item]\n",
    "        # print(ser1, ser2)\n",
    "        ss = simFunc(ser1, ser2)\n",
    "        # print(ss, user_score_other_item)\n",
    "        sim_total += ss\n",
    "        user_sim_total += user_score_other_item * ss\n",
    "\n",
    "        \n",
    "    if sim_total == 0:\n",
    "        return 0\n",
    "    \n",
    "    else:\n",
    "        return user_sim_total / sim_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The commands below predict  the scores for products not yet reviewed by R0, using function built above: scorePred.\n",
    "We use the cosine similarity because if a product has only one value of review (e.g. all 5s), then the standard deviation is 0 and the correlation coefficient is not calculable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "SVDpreds = {}\n",
    "for item in r0_not_rev:\n",
    "    SVDpreds[item] = scorePredSVD(reshaped_reviews, 'R0', item, svd_df, simFunc = c_sim, rev_items = r0_rev_prods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(SVDpreds).sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id=\"q09\"></a>\n",
    "[Return to top](#questions)\n",
    "### Question 09\n",
    "\n",
    "SVD is a kind of:\n",
    "- a) Variance reduction.\n",
    "- b) Special type of array in Python.\n",
    "- c) Dimensionality reduction.\n",
    "- d) Description of central tendency.\n",
    "\n",
    "Assign the character associated with your choice as a string to the variable ans1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### GRADED\n",
    "# SVD is a kind of:\n",
    "# a) Variance reduction.\n",
    "# b) Special type of array in Python.\n",
    "# c) Dimensionality reduction.\n",
    "# d) Description of central tendency.\n",
    "\n",
    "#Assign the character associated with your choice as a string to the variable ans1.\n",
    "### YOUR SOLUTION HERE\n",
    "\n",
    "ans1 = ''\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Q-09",
     "locked": true,
     "points": "5",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "<a id = \"surprise\"></a>\n",
    "### Surprise - Python Package\n",
    "[`Surprise`](http://surpriselib.com) is a Python package which implements a number of tools for building and testing recommender systems. The documentation can be found [here](https://surprise.readthedocs.io/en/stable/).\n",
    "\n",
    "**THE FOLLOWING CODE WILL NOT RUN ON VOCAREUM. WE JUST PROVIDE EXAMPLES IN CASE YOU CHOOSE TO USE `SURPRISE` IN YOUR OWN ENVIRONMENT**  \n",
    "\n",
    "\n",
    "To install surprise, run:  \n",
    "\n",
    "`conda install -c conda-forge scikit-surprise`  \n",
    "\n",
    "in the Anaconda Prompt. After the installation, you might have to reinstall or update scipy, and restart Kernel by doing\n",
    "\n",
    "`conda install -c anaconda scipy`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "Below is [example code from the surprise documentation](https://surprise.readthedocs.io/en/stable/getting_started.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# from surprise import SVD\n",
    "# from surprise import Dataset\n",
    "# from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# # Load the movielens-100k dataset (download it if needed),\n",
    "# data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# # We'll use the famous SVD algorithm.\n",
    "# algo = SVD()\n",
    "\n",
    "# # Run 5-fold cross-validation and print results\n",
    "# cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "[Loading in a df](https://surprise.readthedocs.io/en/stable/dataset.html?highlight=pandas#surprise.dataset.Dataset.load_from_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from surprise import BaselineOnly\n",
    "# from surprise import Reader\n",
    "\n",
    "# # when using a df to load in data, the columns must be:\n",
    "# # user, product, rating, in that order\n",
    "# # a reader must be defined to describe the rating_scale\n",
    "# reader = Reader(rating_scale=(0,5))\n",
    "\n",
    "# data = Dataset.load_from_df(rev_df, reader=reader)\n",
    "\n",
    "# # We can now use this dataset as we please, e.g. calling cross_validate\n",
    "# cross_validate(BaselineOnly(), data, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "### One final note: \n",
    "\n",
    "This project has based its recommendations of comparing the similarity of different *items*.  Using the same technique, it is also possible to calculate the similarity of *users*. The reason why *items* is usually the default choice is that there are usually fewer items than users. This decreases the number of similarity calculations required. \n",
    "\n",
    "For example, in our data, we had roughly 3.5k items and 5.5k users. When using a complete dataset from a specific source, this difference will be more significant."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
